name: Weekly - Update LOTS Project 
on:
  schedule:
    - cron: '30 12 * * 0'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update-lottunnels:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install Python Dependencies
        run: pip install PyYAML

      - name: Create Output Directory
        run: mkdir -p output

      - name: Process LOTS Project Website
        run: |
          echo "Processing LOTS Project..."
          
          # On installe BeautifulSoup si ce n'est pas déjà fait
          pip install beautifulsoup4 requests

          python3 - <<EOF
          import requests
          from bs4 import BeautifulSoup
          import csv
          import sys

          url = "https://lots-project.com"
          output_file = "output/lots_project.csv"

          try:
              response = requests.get(url, timeout=15)
              response.raise_for_status()
              soup = BeautifulSoup(response.content, 'html.parser')
              table = soup.find('table')     
              if not table:
                  print("⚠️ Warning: No table found on lots-project.com")
                  sys.exit(0)
              headers = []
              header_row = table.find('tr')
              if header_row:
                  headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]
              if not headers:
                  headers = ["Domain", "Tags", "Service Provider"]
              rows = []
              for tr in table.find_all('tr')[1:]:
                  cells = tr.find_all('td')
                  if not cells:
                      continue  
                  row_data = [cell.get_text(separator=' ', strip=True) for cell in cells]   
                  if row_data:
                      rows.append(row_data)
              with open(output_file, 'w', newline='', encoding='utf-8') as f:
                  writer = csv.writer(f)
                  writer.writerow(headers)
                  writer.writerows(rows)              
              print(f"✅ Success: {len(rows)} trusted sites extracted to {output_file}")
          except Exception as e:
              print(f"❌ Error scraping LOTS: {e}")
              sys.exit(0)
          EOF

      - name: Commit and push changes
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          git add output/lots_project.csv
          
          if git diff --staged --quiet; then
            echo "No changes detected."
          else
            git commit -m "update refsets $(date +'%Y-%m-%d')"
            git push
          fi