name: Weekly - Update FileSec Project
on:
  schedule:
    - cron: '30 18 * * 0'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update-filesec:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Create Output Directory
        run: mkdir -p output

      - name: Process FileSec.io Website
        run: |
          pip install beautifulsoup4 requests
          python3 - <<EOF
          import requests
          from bs4 import BeautifulSoup
          import csv
          import sys
          url = "https://filesec.io"
          output_file = "output/filesec_project.csv"
          headers = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'
          }

          try:
              response = requests.get(url, headers=headers, timeout=20)
              response.raise_for_status()  
              soup = BeautifulSoup(response.content, 'html.parser')
              table = soup.find('table')
              if not table:
                  print("⚠️ Warning: No table found on filesec.io")
                  sys.exit(0)
              headers_list = []
              header_row = table.find('tr')
              if header_row:
                  headers_list = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]
              if not headers_list:
                  headers_list = ["Extension", "Description", "Tags", "OS"]
              rows = []
              for tr in table.find_all('tr')[1:]: # Skip header
                  cells = tr.find_all('td')
                  if not cells:
                      continue    
                  row_data = []
                  for cell in cells:
                      text = cell.get_text(separator=' ', strip=True)
                      row_data.append(text)                
                  if any(row_data): # Évite les lignes vides
                      rows.append(row_data)
              with open(output_file, 'w', newline='', encoding='utf-8') as f:
                  writer = csv.writer(f)
                  writer.writerow(headers_list)
                  writer.writerows(rows)      
              print(f"✅ Success: {len(rows)} file extensions extracted to {output_file}")
          except Exception as e:
              print(f"❌ Error scraping FileSec: {e}")
              sys.exit(0)
          EOF

      - name: Commit and push changes
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          git add output/filesec_project.csv
          
          if git diff --staged --quiet; then
            echo "No changes detected."
          else
            git commit -m "update refsets $(date +'%Y-%m-%d')"
            git push
          fi